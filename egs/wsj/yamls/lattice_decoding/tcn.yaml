Datasets:
  dev:
    batch_size: 16
    class_name: att_speech.data.ConfigurableData
    dataset:
      class_name: egs.wsj.data.WSJDataset
      data_dir: exp/wsjs5/pydata/fbank80/test_dev93/
      feat_dim:
      - -1
      - 3
      - 81
      feat_dim_shuffle:
      - 0
      - 2
      - 1
      feat_input_file: feats.scp
      feat_pipeline: apply-cmvn exp/wsjs5/pydata/fbank80/train_si284/cmvn %s %s 2>/dev/null
      vocab_file: egs/wsj/vocabulary.txt
    num_workers: 1
    pin_memory: false
  test:
    batch_size: 16
    class_name: att_speech.data.ConfigurableData
    dataset:
      class_name: egs.wsj.data.WSJDataset
      data_dir: exp/wsjs5/pydata/fbank80/test_eval92/
      feat_dim:
      - -1
      - 3
      - 81
      feat_dim_shuffle:
      - 0
      - 2
      - 1
      feat_input_file: feats.scp
      feat_pipeline: apply-cmvn exp/wsjs5/pydata/fbank80/train_si284/cmvn %s %s 2>/dev/null
      vocab_file: egs/wsj/vocabulary.txt
    num_workers: 1
    pin_memory: false
  train:
    batch_size: 20
    class_name: att_speech.data.ConfigurableData
    dataset:
      class_name: egs.wsj.data.WSJDataset
      data_dir: exp/wsjs5/pydata/fbank80/train_si284/
      feat_dim:
      - -1
      - 3
      - 81
      feat_dim_shuffle:
      - 0
      - 2
      - 1
      feat_input_file: feats.scp
      feat_pipeline: apply-cmvn exp/wsjs5/pydata/fbank80/train_si284/cmvn %s %s 2>/dev/null
      vocab_file: egs/wsj/vocabulary.txt
    num_workers: 2
    pin_memory: false
    shuffle: true
Model:
  class_name: att_speech.models.SpeechModel
  decoder:
    att_hidden_size: 64
    attention_temperature: 1.25
    beam_size: 1
    branching_threshold: 0.0
    class_name: att_speech.modules.tcn.AttentionDecoderTCN
    dilation_sizes:
    - 1
    - 2
    dropout_p: 0.3
    kernel_size: 3
    length_normalization: 0.6
    tcn_hidden_size: 384
    tcn_layers_per_block: 2
  encoder:
    class_name: att_speech.modules.encoders.DeepSpeech2
    conv_kernel_sizes:
    - - 7
      - 7
    - - 7
      - 7
    conv_strides:
    - - 1
      - 2
    - - 3
      - 1
    rnn_hidden_size: 320
    rnn_nb_layers: 4
    rnn_normalization: none
Trainer:
  checkpointer:
    every_n_hours: 6
  hooks:
    GradientClipping:
      clip_norm: 50.0
    LinearIncreaseWeightNoise:
      start_iteration: 20000
      weight_noise:
        decoder: 0.02
        encoder: 0.2
  init_phase_iters: 10
  learning_rate: 0.0004
  learning_rate_scheduler:
    class_name: att_speech.schedulers.MultiStepLR
    gamma: 0.5
    milestones:
    - 30
    - 45
    - 60
    - 70
    - 80
    - 90
  num_epochs: 100
  optimizer_name: Adam
